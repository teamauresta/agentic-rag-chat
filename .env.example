# ── LLM Backend ──
# Any OpenAI-compatible API (vLLM, Ollama, OpenAI, Together, etc.)
LLM_URL=http://localhost:8000/v1
LLM_API_KEY=sk-your-api-key
LLM_MODEL=your-model-name

# ── Authentication ──
# Comma-separated API keys for client access
CLIENT_API_KEYS=change-me-in-production

# ── Redis ──
REDIS_URL=redis://localhost:6379/0

# ── PostgreSQL (pgvector) ──
RAG_DB_HOST=localhost
RAG_DB_PORT=5432
RAG_DB_USER=sotastack
RAG_DB_PASS=sotastack
RAG_DB_NAME=sotastack_agent

# ── RAG Settings ──
RAG_ENABLED=true
RAG_TOP_K=5
RAG_MIN_SIMILARITY=0.3

# ── Rate Limiting ──
RATE_LIMIT_PER_MIN=20
RATE_LIMIT_PER_HOUR_SESSION=100

# ── Server ──
HOST=0.0.0.0
PORT=8083

# ── CORS ──
# Comma-separated origins, or * for all
CORS_ORIGINS=*

# ── Context Window ──
MAX_TOKENS_CONTEXT=28000
MAX_MESSAGE_LENGTH=2000
